{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMV+HIW5fNFS33wDVr+cQy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saksham22-kb/Generative-AI/blob/main/SetUpand_environment_Using_GROQAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GROQ **SETUP**\n",
        "\n"
      ],
      "metadata": {
        "id": "DEkxPsrfJUDq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLkUSBeNIm18",
        "outputId": "7c880077-90c4-410e-c81e-74b4d9e5f2f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API key active \n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "GROQ_API_KEY=userdata.get(\"groq\")\n",
        "if GROQ_API_KEY:\n",
        "  print(\"API key active \")\n",
        "else:\n",
        "  print(\"API not working\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_groq\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8750G52-NfBt",
        "outputId": "7b5c9b49-5a7b-4146-e030-4a4b3f74a84a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_groq in /usr/local/lib/python3.12/dist-packages (1.0.1)\n",
            "Requirement already satisfied: groq<1.0.0,>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from langchain_groq) (0.34.1)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain_groq) (1.0.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (4.15.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain_groq) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain_groq) (0.4.42)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain_groq) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain_groq) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain_groq) (8.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq<1.0.0,>=0.30.0->langchain_groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain_groq) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain_groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain_groq) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.2->langchain_groq) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain_groq) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain_groq) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain_groq) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain_groq) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq<1.0.0,>=0.30.0->langchain_groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq<1.0.0,>=0.30.0->langchain_groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq<1.0.0,>=0.30.0->langchain_groq) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain_groq) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain_groq) (2.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "llm=ChatGroq(model=\"openai/gpt-oss-20b\",\n",
        "             api_key=GROQ_API_KEY,\n",
        "             temperature=0.7,\n",
        "             max_tokens=256)"
      ],
      "metadata": {
        "id": "01-iUUq_NtE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Respond.content don't gives meta data\n",
        "where as respond gives meta data"
      ],
      "metadata": {
        "id": "fkhhcqxTPV9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "respond=llm.invoke(\"who are you \")\n",
        "print(respond)\n",
        "\n",
        "text=respond.content\n",
        "summary=llm.invoke(f\"summarize it in two sentence:\\n\\n{text}\")\n",
        "print(\"\\nsummary:\\n\",summary.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Dq_ZoWjPFUa",
        "outputId": "42010124-cf43-4197-b26f-ec5f1584d421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='I’m ChatGPT, a large language model created by OpenAI. I’m here to help answer questions, brainstorm ideas, explain concepts, and assist with a wide variety of tasks—just let me know what you need!' additional_kwargs={'reasoning_content': 'The user asks \"who are you\". We should respond in a friendly manner, explaining that we are ChatGPT, a large language model trained by OpenAI. We can mention that we can answer questions, help with tasks, etc. Should be concise.'} response_metadata={'token_usage': {'completion_tokens': 106, 'prompt_tokens': 75, 'total_tokens': 181, 'completion_time': 0.103860422, 'prompt_time': 0.004092855, 'queue_time': 0.019861915, 'total_time': 0.107953277, 'completion_tokens_details': {'reasoning_tokens': 52}}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_37c9245f64', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--c97fb934-2c81-4cfa-b9b9-d8f586dadc0b-0' usage_metadata={'input_tokens': 75, 'output_tokens': 106, 'total_tokens': 181, 'output_token_details': {'reasoning': 52}}\n",
            "\n",
            "summary:\n",
            " I’m ChatGPT, a large language model created by OpenAI. I can answer questions, brainstorm ideas, explain concepts, and help with a wide range of tasks—just tell me what you need!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Low temperature (factual)\n",
        "\n",
        "cold=ChatGroq(model=\"openai/gpt-oss-20b\", api_key=GROQ_API_KEY, temperature=0.8)\n",
        "print(\"Cold Response:\", cold.invoke(\"Suggest one creative use of AI in education\").content)\n",
        "print(\"-\"*50)\n",
        "\n",
        "#High temperature (creative)\n",
        "\n",
        "hot=ChatGroq(model=\"openai/gpt-oss-20b\", api_key=GROQ_API_KEY, temperature=0.9)\n",
        "print(\"\\nHot Response:\", hot.invoke(\"Suggest one creative use of AI in education\").content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rz8TjT2LSx6p",
        "outputId": "f8555c96-d71c-4885-9b79-e40f42b7aa93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cold Response: **AI‑Powered “Learning Concierge” for Every Student**\n",
            "\n",
            "Create a conversational AI that acts as a personalized learning concierge, available 24/7.  \n",
            "- **Context‑aware tutoring**: It listens to a student’s current assignment, notes the learning style, and instantly generates micro‑lessons, interactive quizzes, or visual explanations tailored to that moment.  \n",
            "- **Real‑time feedback loop**: As the student works, the AI tracks progress, identifies misconceptions, and nudges them with hints or analogies—much like a live teaching assistant.  \n",
            "- **Curriculum roadmap**: It maps out a flexible learning path, suggesting next topics, supplemental resources, and projects that align with the student’s goals and pace.  \n",
            "- **Social‑empathy layer**: By integrating sentiment analysis, the AI can detect frustration or boredom and adjust tone or provide motivational prompts.  \n",
            "\n",
            "This concierge turns every device into a dynamic, empathetic tutor that scales to any class size while preserving the human touch of individualized guidance.\n",
            "--------------------------------------------------\n",
            "\n",
            "Hot Response: **Idea: The “AI‑Facilitated Empathy Lab” – a virtual role‑playing studio that lets students step into the shoes of people from any time, place, or walk of life**\n",
            "\n",
            "---\n",
            "\n",
            "### What it is\n",
            "\n",
            "An AI‑powered, immersive learning environment (think of it as a blend of a VR/AR sandbox, a conversational agent, and a dynamic storytelling engine). Students choose a “character” (e.g., a 19th‑century abolitionist, a refugee child in 2023, a pioneering woman scientist in the 1960s) and engage in a guided, interactive scenario that unfolds in real time. The AI character speaks, reacts, and adapts to the student’s questions, emotions, and choices, all while the student records or streams their experience for reflection and assessment.\n",
            "\n",
            "---\n",
            "\n",
            "### How it works\n",
            "\n",
            "| Layer | Function | Tech Stack |\n",
            "|-------|----------|------------|\n",
            "| **Persona Engine** | Generates a realistic, historically/ culturally‑accurate avatar with voice, facial expression, and behavioral patterns. | Large‑language‑model fine‑tuned on biographical data + multimodal diffusion model for visual rendering |\n",
            "| **Dialogue Manager** | Handles real‑time conversation, maintaining context, emotional tone, and knowledge depth. | GPT‑4‑based chatbot + reinforcement‑learning dialogue policy |\n",
            "| **Scenario Designer** | Teachers build “missions” (e.g., “Debate the morality of slavery with a contemporary activist”) with branching outcomes. | Visual storyboard tool with drag‑and‑drop, integrated with the AI model via API |\n",
            "| **Learning Analytics** | Tracks student engagement, empathy scores, factual accuracy, and reflective insights. | Natural language processing on transcripts + sentiment analysis + knowledge‑gap detection |\n",
            "| **Reflection Hub** | Students write or record a post‑experience reflection; AI offers prompts and feedback. | Summarization & sentiment models + human‑in‑the‑loop review panel |\n",
            "\n",
            "---\n",
            "\n",
            "### Why it’s creative\n",
            "\n",
            "- **Empathy + Critical Thinking**: By interacting with a living, breathing “other,” students practice perspective‑taking while simultaneously critiquing assumptions and evidence.\n",
            "- **Scalable, Diverse Content**: One AI engine can represent thousands of characters from any era or culture, far beyond what a human teacher could realistically cover.\n",
            "- **Safe, Ethical Exploration**: Sensitive topics (e.g., trauma, discrimination) can be simulated with built‑in safety nets (tone‑down options, emotional‑support prompts) while preserving authenticity.\n",
            "- **Multimodal Learning**: Visual, auditory, and kinesthetic cues are all present, catering to varied learning styles.\n",
            "\n",
            "---\n",
            "\n",
            "### Example Implementation in a Classroom\n",
            "\n",
            "1. **Pre‑Lab Prep**  \n",
            "   - The teacher selects the character “Malala Yousafzai” for a unit on girls’ education.  \n",
            "   - They design a scenario: “Malala visits a school in a rural village and must convince the local leaders to support girls’ education.”\n",
            "\n",
            "2. **Lab Session**  \n",
            "   - Students pair up and each takes on a role (e.g., Malala, a local elder, a skeptical parent).  \n",
            "   - Using a tablet or VR headset, the AI delivers Malala’s voice, mannerisms, and back‑story.  \n",
            "   - Students ask questions, propose solutions, and negotiate. The AI adapts her responses based on the students’ arguments, the evidence they bring, and her “mood” (e.g., frustrated, hopeful).\n",
            "\n",
            "3. **Post‑Lab Reflection**  \n",
            "   - Students write a short diary entry from Malala’s perspective or record a video reflection.  \n",
            "   - The AI offers feedback on empathy depth and factual accuracy, suggesting resources for further reading.\n",
            "\n",
            "4. **Assessment**  \n",
            "   - The reflection is graded on a rubric that includes empathy, critical analysis, and evidence usage.  \n",
            "   - The teacher reviews the AI’s transcript to check for misconceptions and can provide targeted follow‑up.\n",
            "\n",
            "---\n",
            "\n",
            "### Benefits\n",
            "\n",
            "| Benefit | Detail |\n",
            "|---------|--------|\n",
            "| **Deep Engagement** | Interactive, story‑driven format keeps students actively involved. |\n",
            "| **Personalized Pace** | AI can slow down, repeat, or provide additional context for struggling students. |\n",
            "| **Cross‑Curricular** | Works for history, literature, social studies, language arts, and even STEM ethics. |\n",
            "| **Data‑Driven Insight** | Teachers get granular analytics on student misconceptions and emotional states. |\n",
            "| **Scalable Empathy Training** | One AI instance can serve hundreds of classrooms worldwide. |\n",
            "\n",
            "---\n",
            "\n",
            "### Challenges & Mitigation\n",
            "\n",
            "- **Authenticity vs. Bias**: Continuous human oversight and diverse data curation are essential to avoid reinforcing stereotypes.  \n",
            "- **Privacy**: All student data must be anonymized, stored securely, and compliant with FERPA/GDPR.  \n",
            "- **Cost**: Leveraging open‑source models and cloud‑based APIs can reduce hardware demands; schools can pool resources.  \n",
            "- **Teacher Training**: Professional development modules on scenario design and AI ethics will be crucial.\n",
            "\n",
            "---\n",
            "\n",
            "### Bottom Line\n",
            "\n",
            "The **AI‑Facilitated Empathy Lab** transforms passive content consumption into a lived experience. By letting students converse with AI‑embodied historical and contemporary figures, we blend storytelling, critical inquiry, and emotional intelligence into one dynamic, scalable classroom tool—an AI‑driven bridge between knowledge and empathy.\n"
          ]
        }
      ]
    }
  ]
}